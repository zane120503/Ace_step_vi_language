# HÆ°á»›ng dáº«n Train LoRA Tiáº¿ng Viá»‡t cho ACE-Step

## ğŸ“‹ TÃ³m táº¯t nhanh

1. **Chuáº©n bá»‹ dá»¯ liá»‡u**: 3 file cho má»—i bÃ i hÃ¡t (MP3 + prompt.txt + lyrics.txt)
2. **Convert dataset**: Cháº¡y `convert2hf_dataset.py`
3. **Train LoRA**: Cháº¡y `trainer.py` vá»›i config Ä‘Ã£ tá»‘i Æ°u cho RTX 3050
4. **Load LoRA**: Sá»­ dá»¥ng checkpoint trong web UI

---

## A. Chuáº©n bá»‹ dá»¯ liá»‡u

### Cáº¥u trÃºc thÆ° má»¥c `data/`:

```
data/
â”œâ”€â”€ vi_song_001.mp3
â”œâ”€â”€ vi_song_001_prompt.txt
â””â”€â”€ vi_song_001_lyrics.txt
â”œâ”€â”€ vi_song_002.mp3
â”œâ”€â”€ vi_song_002_prompt.txt
â””â”€â”€ vi_song_002_lyrics.txt
...
```

### Format file:

#### `vi_song_001_prompt.txt`:
```
pop ballad, giá»ng ná»¯, piano, guitar, cháº­m, buá»“n, 85 bpm, minor key, emotional
```

**Gá»£i Ã½ tags tiáº¿ng Viá»‡t:**
- Genre: `pop`, `ballad`, `rock`, `rap`, `electronic`, `folk`, `nháº¡c trá»¯ tÃ¬nh`
- Giá»ng: `giá»ng nam`, `giá»ng ná»¯`, `giá»ng tráº» em`, `há»£p xÆ°á»›ng`
- Nháº¡c cá»¥: `piano`, `guitar`, `trá»‘ng`, `violin`, `sÃ¡o`, `Ä‘Ã n tranh`
- Mood: `vui váº»`, `buá»“n`, `lÃ£ng máº¡n`, `máº¡nh máº½`, `nháº¹ nhÃ ng`
- Tempo: `85 bpm`, `120 bpm`, `cháº­m`, `nhanh`, `vá»«a pháº£i`
- Key: `major key`, `minor key`, `C major`, `A minor`

#### `vi_song_001_lyrics.txt`:
```
[Verse 1]
ÄÃªm neon váº«n sÃ¡ng ngá»i
Phá»‘ xa vang tiáº¿ng gá»i má»i
Nhá»‹p tim theo bÆ°á»›c chÃ¢n ai
Láº«n trong Ã¢m sáº¯c nÆ¡i nÃ y

[Chorus]
Cá»© báº­t lá»›n Ä‘á»ƒ giÃ³ hÃ¡t
Cho ngá»n lá»­a nÃ y chÃ¡y khÃ¡t
Trong nhá»‹p Ä‘iá»‡u ta chung Ä‘Ã´i
ÄÃªm ngÃ¢n vang khÃºc ca nÃ y
```

**LÆ°u Ã½:**
- TÃªn file pháº£i khá»›p chÃ­nh xÃ¡c: `filename.mp3`, `filename_prompt.txt`, `filename_lyrics.txt`
- Lyrics nÃªn cÃ³ cáº¥u trÃºc rÃµ rÃ ng vá»›i `[Verse]`, `[Chorus]`, `[Bridge]`
- Sá»­ dá»¥ng tiáº¿ng Viá»‡t cÃ³ dáº¥u Ä‘áº§y Ä‘á»§

---

## B. Cháº¡y Training (2 cÃ¡ch)

### CÃ¡ch 1: DÃ¹ng script tá»± Ä‘á»™ng (Khuyáº¿n nghá»‹)

**PowerShell:**
```powershell
.\run_train_vi.ps1
```

**Hoáº·c Windows Batch:**
```cmd
run_train_vi.bat
```

### CÃ¡ch 2: Cháº¡y thá»§ cÃ´ng tá»«ng bÆ°á»›c

#### BÆ°á»›c 1: Convert dataset
```bash
python convert2hf_dataset.py --data_dir "./data" --repeat_count 2000 --output_name "vi_lora_dataset"
```

**Giáº£i thÃ­ch:**
- `--repeat_count 2000`: NhÃ¢n báº£n dá»¯ liá»‡u 2000 láº§n (há»¯u Ã­ch náº¿u dataset nhá»)
- `--output_name`: TÃªn thÆ° má»¥c dataset output

#### BÆ°á»›c 2: Train LoRA
```bash
python trainer.py \
    --num_nodes 1 \
    --devices 1 \
    --dataset_path "./vi_lora_dataset" \
    --exp_name "vi_lora_small" \
    --lora_config_path "config/vi_lora_config.json" \
    --learning_rate 1e-4 \
    --accumulate_grad_batches 8 \
    --precision 16 \
    --num_workers 2 \
    --max_steps 20000 \
    --every_n_train_steps 500 \
    --shift 3.0 \
    --checkpoint_dir "./exps/checkpoints/vi_lora" \
    --logger_dir "./exps/logs/vi_lora" \
    --epochs -1 \
    --every_plot_step 2000 \
    --val_check_interval None \
    --gradient_clip_val 0.5 \
    --gradient_clip_algorithm "norm"
```

---

## C. Tham sá»‘ tá»‘i Æ°u cho RTX 3050 (6GB VRAM)

| Tham sá»‘ | GiÃ¡ trá»‹ | LÃ½ do |
|---------|---------|-------|
| `precision` | `16` | FP16 giáº£m 50% VRAM |
| `accumulate_grad_batches` | `8` | MÃ´ phá»ng batch size lá»›n mÃ  khÃ´ng tá»‘n VRAM |
| `num_workers` | `2` | Giáº£m táº£i CPU |
| `r` (LoRA) | `16` | Rank nhá» = Ã­t VRAM |
| `max_steps` | `20000` | Äá»§ Ä‘á»ƒ train LoRA, cÃ³ thá»ƒ tÄƒng náº¿u cáº§n |

### Náº¿u GPU máº¡nh hÆ¡n (RTX 3090/4090):

- TÄƒng `r` lÃªn `32` hoáº·c `64` trong `config/vi_lora_config.json`
- TÄƒng `accumulate_grad_batches` lÃªn `16` hoáº·c `32`
- TÄƒng `max_steps` lÃªn `50000` hoáº·c `100000`
- TÄƒng `num_workers` lÃªn `4` hoáº·c `8`

---

## D. Theo dÃµi Training

### Logs:
- **TensorBoard**: `./exps/logs/vi_lora/`
- **Checkpoints**: `./exps/checkpoints/vi_lora/`

### Xem TensorBoard (náº¿u cÃ³):
```bash
tensorboard --logdir ./exps/logs/vi_lora
```

### Kiá»ƒm tra checkpoint:
Sau má»—i `every_n_train_steps` (500 steps), checkpoint sáº½ Ä‘Æ°á»£c lÆ°u táº¡i:
```
./exps/checkpoints/vi_lora/vi_lora_small/checkpoints/epoch=*.ckpt
```

---

## E. Load LoRA vÃ o Web UI

Sau khi training xong:

1. **TÃ¬m file checkpoint**: 
   - ThÆ°á»ng lÃ  file `.ckpt` hoáº·c `.safetensors` trong `./exps/checkpoints/vi_lora/`

2. **Trong web UI ACE-Step**:
   - VÃ o pháº§n **LoRA Settings**
   - **LoRA Name or Path**: Nháº­p Ä‘Æ°á»ng dáº«n Ä‘áº¿n file checkpoint
   - **LoRA Weight**: Báº¯t Ä‘áº§u vá»›i `0.6-0.8`, Ä‘iá»u chá»‰nh theo káº¿t quáº£
   - **Generate** vá»›i prompt vÃ  lyrics tiáº¿ng Viá»‡t

3. **VÃ­ dá»¥ prompt trong UI**:
   ```
   pop ballad, giá»ng ná»¯, piano, guitar, cháº­m, buá»“n, 85 bpm
   ```

---

## F. Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p

### 1. Out of Memory (OOM)

**Giáº£i phÃ¡p:**
- Giáº£m `accumulate_grad_batches` xuá»‘ng `4` hoáº·c `2`
- Giáº£m `r` trong config xuá»‘ng `8`
- Äáº£m báº£o `precision=16`
- ÄÃ³ng cÃ¡c á»©ng dá»¥ng khÃ¡c Ä‘ang dÃ¹ng GPU

### 2. Lá»—i convert dataset

**Kiá»ƒm tra:**
- TÃªn file pháº£i Ä‘Ãºng pattern: `name.mp3`, `name_prompt.txt`, `name_lyrics.txt`
- KhÃ´ng cÃ³ kÃ½ tá»± Ä‘áº·c biá»‡t trong tÃªn file
- File encoding pháº£i lÃ  UTF-8

### 3. Training cháº­m

**Tá»‘i Æ°u:**
- TÄƒng `num_workers` náº¿u CPU máº¡nh
- Giáº£m `every_n_train_steps` Ä‘á»ƒ Ã­t checkpoint hÆ¡n
- Kiá»ƒm tra GPU utilization báº±ng `nvidia-smi`

### 4. Loss khÃ´ng giáº£m

**Äiá»u chá»‰nh:**
- Giáº£m `learning_rate` xuá»‘ng `5e-5`
- TÄƒng `max_steps`
- Kiá»ƒm tra cháº¥t lÆ°á»£ng dá»¯ liá»‡u (prompt vÃ  lyrics cÃ³ khá»›p audio khÃ´ng)

---

## G. Tips & Best Practices

1. **Dataset cháº¥t lÆ°á»£ng > sá»‘ lÆ°á»£ng**: 20-50 bÃ i hÃ¡t cháº¥t lÆ°á»£ng tá»‘t hÆ¡n 100 bÃ i kÃ©m cháº¥t lÆ°á»£ng
2. **Äa dáº¡ng phong cÃ¡ch**: Bao gá»“m nhiá»u genre, giá»ng hÃ¡t, mood khÃ¡c nhau
3. **Lyrics chÃ­nh xÃ¡c**: Lyrics pháº£i khá»›p vá»›i audio, Ä‘áº·c biá»‡t lÃ  timing
4. **Prompt mÃ´ táº£ chi tiáº¿t**: CÃ ng chi tiáº¿t cÃ ng tá»‘t
5. **Test thÆ°á»ng xuyÃªn**: Sau má»—i 5000 steps, test LoRA Ä‘á»ƒ xem tiáº¿n Ä‘á»™
6. **Backup checkpoint**: LÆ°u cÃ¡c checkpoint tá»‘t Ä‘á»ƒ cÃ³ thá»ƒ rollback

---

## H. Checklist trÆ°á»›c khi train

- [ ] ÄÃ£ chuáº©n bá»‹ Ã­t nháº¥t 10-20 bÃ i hÃ¡t trong thÆ° má»¥c `data/`
- [ ] Má»—i bÃ i cÃ³ Ä‘á»§ 3 file: `.mp3`, `_prompt.txt`, `_lyrics.txt`
- [ ] TÃªn file Ä‘Ãºng pattern
- [ ] ÄÃ£ táº¡o `config/vi_lora_config.json`
- [ ] ÄÃ£ kÃ­ch hoáº¡t mÃ´i trÆ°á»ng `ace_step`
- [ ] GPU cÃ³ Ä‘á»§ VRAM (kiá»ƒm tra báº±ng `nvidia-smi`)
- [ ] ÄÃ£ backup dá»¯ liá»‡u quan trá»ng

---

## I. TÃ i liá»‡u tham kháº£o

- File gá»‘c: `TRAIN_INSTRUCTION.md`
- Config máº«u: `config/zh_rap_lora_config.json`
- Script convert: `convert2hf_dataset.py`
- Trainer: `trainer.py`

---

**ChÃºc báº¡n train thÃ nh cÃ´ng! ğŸµ**

