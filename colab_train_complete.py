"""
ğŸ¯ HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG:
1. Má»Ÿ Google Colab: https://colab.research.google.com/
2. Táº¡o notebook má»›i
3. Chá»n Runtime â†’ Change runtime type â†’ GPU
4. Copy tá»«ng cell dÆ°á»›i Ä‘Ã¢y vÃ o Colab vÃ  cháº¡y
"""

# ============================================
# CELL 1: Mount Google Drive
# ============================================
from google.colab import drive
drive.mount('/content/drive')

# ============================================
# CELL 2: Clone Repository
# ============================================
# Clone tá»« repository tiáº¿ng Viá»‡t (Ä‘Ã£ cÃ³ config vÃ  dataset cho tiáº¿ng Viá»‡t)
!git clone https://github.com/zane120503/Ace_step_vi_language.git
%cd Ace_step_vi_language

# ============================================
# CELL 3: CÃ i Ä‘áº·t Dependencies
# ============================================
# Xá»­ lÃ½ táº¥t cáº£ dependency conflicts má»™t cÃ¡ch thÃ´ng minh

print("ğŸ”§ Äang fix cÃ¡c dependency conflicts...")

# BÆ°á»›c 1: Uninstall cÃ¡c packages cÃ³ conflict Ä‘á»ƒ clean install
!pip uninstall -y numpy protobuf fsspec tensorboard 2>/dev/null || true

# BÆ°á»›c 2: CÃ i Ä‘áº·t cÃ¡c packages vá»›i version cá»‘ Ä‘á»‹nh (trÆ°á»›c khi cÃ i requirements.txt)
!pip install -q --no-deps "numpy>=1.26.0,<2.1.0"
!pip install -q --no-deps "protobuf>=3.20.3,<6.0.0,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5"
!pip install -q --no-deps "fsspec>=2023.1.0,<=2024.12.0"
!pip install -q --no-deps "tensorboard==2.19.0"
!pip install -q "jedi>=0.16"

# BÆ°á»›c 3: CÃ i Ä‘áº·t dependencies chÃ­nh
print("ğŸ“¦ Äang cÃ i Ä‘áº·t dependencies chÃ­nh...")
!pip install -q pytorch-lightning transformers accelerate

# BÆ°á»›c 4: CÃ i Ä‘áº·t requirements.txt vá»›i --no-deps Ä‘á»ƒ trÃ¡nh conflicts
print("ğŸ“¦ Äang cÃ i Ä‘áº·t requirements.txt (bá» qua dependency checks)...")
!pip install -q --no-deps -r requirements.txt 2>&1 | head -20 || true

# BÆ°á»›c 5: Force reinstall cÃ¡c packages quan trá»ng vá»›i version Ä‘Ãºng
print("ğŸ”§ Äang lock cÃ¡c packages quan trá»ng á»Ÿ version Ä‘Ãºng...")
!pip install -q --force-reinstall --no-deps "numpy>=1.26.0,<2.1.0" 2>/dev/null || true
!pip install -q --force-reinstall --no-deps "protobuf>=3.20.3,<6.0.0,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5" 2>/dev/null || true
!pip install -q --force-reinstall --no-deps "fsspec>=2023.1.0,<=2024.12.0" 2>/dev/null || true
!pip install -q --force-reinstall --no-deps "tensorboard==2.19.0" 2>/dev/null || true

print("âœ“ ÄÃ£ cÃ i Ä‘áº·t dependencies")
print("â„¹ ÄÃ£ fix vÃ  lock cÃ¡c conflicts: numpy, protobuf, tensorboard, fsspec, jedi")
print("âš ï¸  Má»™t sá»‘ warnings vá» gcsfs/fsspec cÃ³ thá»ƒ xuáº¥t hiá»‡n nhÆ°ng KHÃ”NG áº£nh hÆ°á»Ÿng training")
print("âš ï¸  CÃ¡c warnings vá» dependency conflicts cÃ³ thá»ƒ bá» qua náº¿u training váº«n cháº¡y Ä‘Æ°á»£c")

# ============================================
# CELL 4: Kiá»ƒm tra Dataset vÃ  Config
# ============================================
import os
import glob

# BÆ°á»›c 1: Kiá»ƒm tra Google Drive Ä‘Ã£ Ä‘Æ°á»£c mount chÆ°a
if not os.path.exists("/content/drive"):
    print("âŒ Google Drive chÆ°a Ä‘Æ°á»£c mount!")
    print("   Vui lÃ²ng cháº¡y CELL 1 (Mount Google Drive) trÆ°á»›c!")
    raise FileNotFoundError("Google Drive not mounted!")

# BÆ°á»›c 2: TÃ¬m táº¥t cáº£ cÃ¡c folder cÃ³ tÃªn "vi_lora_dataset" trÃªn Drive
print("ğŸ” Äang tÃ¬m dataset trÃªn Google Drive...")
drive_root = "/content/drive/MyDrive"

# TÃ¬m táº¥t cáº£ folder vi_lora_dataset
found_datasets = []
for root, dirs, files in os.walk(drive_root):
    if "vi_lora_dataset" in dirs:
        full_path = os.path.join(root, "vi_lora_dataset")
        if os.path.isdir(full_path):
            file_count = len(os.listdir(full_path))
            found_datasets.append((full_path, file_count))

# BÆ°á»›c 3: Chá»n dataset phÃ¹ há»£p
dataset_path = None
if found_datasets:
    # Æ¯u tiÃªn dataset trong ace_step_data
    for path, count in found_datasets:
        if "ace_step_data" in path:
            dataset_path = path
            print(f"âœ“ Dataset tÃ¬m tháº¥y táº¡i: {path}")
            print(f"âœ“ Sá»‘ file trong dataset: {count}")
            break
    
    # Náº¿u khÃ´ng cÃ³ trong ace_step_data, dÃ¹ng dataset Ä‘áº§u tiÃªn
    if not dataset_path:
        dataset_path, count = found_datasets[0]
        print(f"âœ“ Dataset tÃ¬m tháº¥y táº¡i: {path}")
        print(f"âœ“ Sá»‘ file trong dataset: {count}")
        if len(found_datasets) > 1:
            print(f"âš ï¸  TÃ¬m tháº¥y {len(found_datasets)} dataset, Ä‘ang dÃ¹ng: {dataset_path}")
            print("   CÃ¡c dataset khÃ¡c:")
            for path, count in found_datasets[1:]:
                print(f"     - {path} ({count} files)")
else:
    # Kiá»ƒm tra cÃ¡c Ä‘Æ°á»ng dáº«n phá»• biáº¿n
    possible_paths = [
        "/content/drive/MyDrive/ace_step_data/vi_lora_dataset",
        "/content/drive/MyDrive/MyDrive/ace_step_data/vi_lora_dataset",  # Náº¿u cÃ³ folder MyDrive trong MyDrive
        "/content/drive/MyDrive/vi_lora_dataset",
        "/content/drive/MyDrive/data/vi_lora_dataset",
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            dataset_path = path
            files = os.listdir(path)
            print(f"âœ“ Dataset tÃ¬m tháº¥y táº¡i: {path}")
            print(f"âœ“ Sá»‘ file trong dataset: {len(files)}")
            break

if not dataset_path:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y dataset!")
    print("\nğŸ“‹ HÆ¯á»šNG DáºªN:")
    print("1. Äáº£m báº£o Google Drive Ä‘Ã£ Ä‘Æ°á»£c mount (CELL 1)")
    print("2. Upload folder 'vi_lora_dataset' lÃªn Google Drive")
    print("3. CÃ³ thá»ƒ Ä‘áº·t á»Ÿ báº¥t ká»³ Ä‘Ã¢u trong MyDrive")
    print("4. Cháº¡y láº¡i cell nÃ y sau khi upload")
    print("\nğŸ’¡ Hoáº·c chá»‰ Ä‘á»‹nh Ä‘Æ°á»ng dáº«n thá»§ cÃ´ng:")
    print("   dataset_path = '/content/drive/MyDrive/your_path/vi_lora_dataset'")

# Kiá»ƒm tra vÃ  copy config
config_paths = [
    "/content/drive/MyDrive/ace_step_data/config/vi_lora_config.json",
    "/content/drive/MyDrive/config/vi_lora_config.json",
    "/content/drive/MyDrive/vi_lora_config.json",
]

config_found = False
for config_path in config_paths:
    if os.path.exists(config_path):
        !cp "{config_path}" config/vi_lora_config.json
        print(f"âœ“ Config file Ä‘Ã£ Ä‘Æ°á»£c copy tá»«: {config_path}")
        config_found = True
        break

if not config_found:
    print("âš ï¸  KhÃ´ng tÃ¬m tháº¥y config file!")
    print("   CÃ³ thá»ƒ sá»­ dá»¥ng config máº·c Ä‘á»‹nh trong repo")
    if os.path.exists("config/vi_lora_config.json"):
        print("âœ“ ÄÃ£ tÃ¬m tháº¥y config trong repo")
    else:
        print("âŒ Cáº§n táº¡o hoáº·c upload config file")

# ============================================
# CELL 5: Táº¡o ThÆ° Má»¥c Output
# ============================================
checkpoint_dir = "/content/drive/MyDrive/ace_step_outputs/checkpoints"
log_dir = "/content/drive/MyDrive/ace_step_outputs/logs"

os.makedirs(checkpoint_dir, exist_ok=True)
os.makedirs(log_dir, exist_ok=True)

print(f"âœ“ Checkpoint dir: {checkpoint_dir}")
print(f"âœ“ Log dir: {log_dir}")

# ============================================
# CELL 6: Kiá»ƒm tra GPU
# ============================================
import torch

print("ğŸ” Kiá»ƒm tra GPU...")
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
    print(f"âœ“ GPU tÃ¬m tháº¥y: {gpu_name}")
    print(f"âœ“ VRAM: {gpu_memory:.2f} GB")
    print(f"âœ“ CUDA available: {torch.cuda.is_available()}")
    print(f"âœ“ CUDA version: {torch.version.cuda}")
    gpu_ok = True
else:
    print("âŒ GPU khÃ´ng available!")
    print("   Vui lÃ²ng chá»n Runtime â†’ Change runtime type â†’ GPU")
    print("   Sau Ä‘Ã³ restart runtime vÃ  cháº¡y láº¡i cell nÃ y")
    gpu_ok = False

# ============================================
# CELL 7: TÃ¬m Checkpoint (Náº¿u Resume)
# ============================================
log_checkpoint_dir = f"{log_dir}/vi_lora/lightning_logs"
checkpoints = glob.glob(f"{log_checkpoint_dir}/*/checkpoints/*.ckpt") if os.path.exists(log_checkpoint_dir) else []

if checkpoints:
    latest_checkpoint = max(checkpoints, key=os.path.getctime)
    print(f"âœ“ TÃ¬m tháº¥y checkpoint: {latest_checkpoint}")
    ckpt_path = latest_checkpoint
    resume = True
else:
    print("â„¹ ChÆ°a cÃ³ checkpoint, sáº½ train tá»« Ä‘áº§u")
    ckpt_path = None
    resume = False

# ============================================
# CELL 8: Báº¯t Äáº§u Training
# ============================================
# Tham sá»‘ training
# Náº¿u dataset_path Ä‘Ã£ Ä‘Æ°á»£c tÃ¬m tháº¥y á»Ÿ CELL 4, sá»­ dá»¥ng nÃ³
# Náº¿u khÃ´ng, tá»± Ä‘á»™ng tÃ¬m láº¡i
if 'dataset_path' not in locals() or dataset_path is None:
    print("ğŸ” Äang tÃ¬m láº¡i dataset...")
    # TÃ¬m láº¡i dataset
    drive_root = "/content/drive/MyDrive"
    found_datasets = []
    
    for root, dirs, files in os.walk(drive_root):
        if "vi_lora_dataset" in dirs:
            full_path = os.path.join(root, "vi_lora_dataset")
            if os.path.isdir(full_path):
                found_datasets.append(full_path)
    
    if found_datasets:
        # Æ¯u tiÃªn dataset trong ace_step_data
        for path in found_datasets:
            if "ace_step_data" in path:
                dataset_path = path
                break
        if not dataset_path:
            dataset_path = found_datasets[0]
        print(f"âœ“ TÃ¬m tháº¥y dataset: {dataset_path}")
    else:
        # Thá»­ cÃ¡c Ä‘Æ°á»ng dáº«n phá»• biáº¿n
        possible_paths = [
            "/content/drive/MyDrive/MyDrive/ace_step_data/vi_lora_dataset",  # TrÆ°á»ng há»£p cÃ³ MyDrive trong MyDrive
            "/content/drive/MyDrive/ace_step_data/vi_lora_dataset",
            "/content/drive/MyDrive/vi_lora_dataset",
            "/content/drive/MyDrive/data/vi_lora_dataset",
        ]
        for path in possible_paths:
            if os.path.exists(path):
                dataset_path = path
                print(f"âœ“ TÃ¬m tháº¥y dataset: {dataset_path}")
                break
    
    if dataset_path is None or not os.path.exists(dataset_path):
        print("âŒ Váº«n khÃ´ng tÃ¬m tháº¥y dataset!")
        print("   Vui lÃ²ng upload dataset lÃªn Google Drive vÃ  chá»‰ Ä‘á»‹nh Ä‘Æ°á»ng dáº«n:")
        print("   dataset_path = '/content/drive/MyDrive/your_path/vi_lora_dataset'")
        raise FileNotFoundError("Dataset not found! Please upload to Google Drive first.")

# XÃ¡c nháº­n dataset path
print(f"ğŸ“‚ Sá»­ dá»¥ng dataset: {dataset_path}")
if not os.path.exists(dataset_path):
    raise FileNotFoundError(f"Dataset path khÃ´ng tá»“n táº¡i: {dataset_path}")

checkpoint_dir = "/content/drive/MyDrive/ace_step_outputs/checkpoints"
log_dir = "/content/drive/MyDrive/ace_step_outputs/logs"

# Build command
cmd = f"""python trainer.py \\
    --num_nodes 1 \\
    --devices 1 \\
    --dataset_path "{dataset_path}" \\
    --exp_name "vi_lora_small" \\
    --lora_config_path "config/vi_lora_config.json" \\
    --learning_rate 1e-4 \\
    --accumulate_grad_batches 4 \\
    --precision 16 \\
    --num_workers 2 \\
    --max_steps 20000 \\
    --every_n_train_steps 100 \\
    --shift 3.0 \\
    --checkpoint_dir "{checkpoint_dir}" \\
    --logger_dir "{log_dir}" \\
    --epochs -1 \\
    --every_plot_step 2000 \\
    --gradient_clip_val 0.5 \\
    --gradient_clip_algorithm "norm" """

# ThÃªm --ckpt_path náº¿u cÃ³ checkpoint
if resume and ckpt_path:
    cmd += f'\\\n    --ckpt_path "{ckpt_path}"'

# Kiá»ƒm tra GPU trÆ°á»›c khi train
if 'gpu_ok' not in locals() or not gpu_ok:
    print("âŒ KhÃ´ng thá»ƒ train vÃ¬ GPU khÃ´ng available!")
    print("   Vui lÃ²ng cháº¡y CELL 6 (Kiá»ƒm tra GPU) trÆ°á»›c!")
    print("   Hoáº·c chá»n Runtime â†’ Change runtime type â†’ GPU")
else:
    print("ğŸš€ Báº¯t Ä‘áº§u training...")
    print("=" * 60)
    print(cmd)
    print("=" * 60)
    
    # Cháº¡y training
    !{cmd}

# ============================================
# CELL 9: Monitor Training (Optional)
# ============================================
# Cháº¡y cell nÃ y trong tab má»›i Ä‘á»ƒ xem log real-time
# (KhÃ´ng cháº¡y cÃ¹ng lÃºc vá»›i training)

# log_dir = "/content/drive/MyDrive/ace_step_outputs/logs/vi_lora/lightning_logs"
# log_files = glob.glob(f"{log_dir}/*/events.out.tfevents.*")
# if log_files:
#     latest_log = max(log_files, key=os.path.getctime)
#     !tail -f {latest_log}

