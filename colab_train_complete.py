"""
üéØ H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG:
1. M·ªü Google Colab: https://colab.research.google.com/
2. T·∫°o notebook m·ªõi
3. Ch·ªçn Runtime ‚Üí Change runtime type ‚Üí GPU
4. Copy t·ª´ng cell d∆∞·ªõi ƒë√¢y v√†o Colab v√† ch·∫°y
"""

# ============================================
# CELL 1: Mount Google Drive
# ============================================
from google.colab import drive
drive.mount('/content/drive')

# ============================================
# CELL 2: Clone Repository
# ============================================
!git clone https://github.com/ace-step/ACE-Step.git
%cd ACE-Step

# ============================================
# CELL 3: C√†i ƒë·∫∑t Dependencies
# ============================================
!pip install -q pytorch-lightning transformers accelerate
!pip install -q -r requirements.txt

# ============================================
# CELL 4: Ki·ªÉm tra Dataset v√† Config
# ============================================
import os
import glob

# Ki·ªÉm tra dataset
dataset_path = "/content/drive/MyDrive/ace_step_data/vi_lora_dataset"
if os.path.exists(dataset_path):
    files = os.listdir(dataset_path)
    print(f"‚úì Dataset t√¨m th·∫•y: {len(files)} files")
else:
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y dataset t·∫°i: {dataset_path}")
    print("   Vui l√≤ng upload dataset l√™n Google Drive!")

# Ki·ªÉm tra v√† copy config
config_path = "/content/drive/MyDrive/ace_step_data/config/vi_lora_config.json"
if os.path.exists(config_path):
    !cp "{config_path}" config/vi_lora_config.json
    print("‚úì Config file ƒë√£ ƒë∆∞·ª£c copy")
else:
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y config t·∫°i: {config_path}")
    print("   Vui l√≤ng upload config file l√™n Google Drive!")

# ============================================
# CELL 5: T·∫°o Th∆∞ M·ª•c Output
# ============================================
checkpoint_dir = "/content/drive/MyDrive/ace_step_outputs/checkpoints"
log_dir = "/content/drive/MyDrive/ace_step_outputs/logs"

os.makedirs(checkpoint_dir, exist_ok=True)
os.makedirs(log_dir, exist_ok=True)

print(f"‚úì Checkpoint dir: {checkpoint_dir}")
print(f"‚úì Log dir: {log_dir}")

# ============================================
# CELL 6: Ki·ªÉm tra GPU
# ============================================
import torch

print("üîç Ki·ªÉm tra GPU...")
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
    print(f"‚úì GPU t√¨m th·∫•y: {gpu_name}")
    print(f"‚úì VRAM: {gpu_memory:.2f} GB")
    print(f"‚úì CUDA available: {torch.cuda.is_available()}")
    print(f"‚úì CUDA version: {torch.version.cuda}")
    gpu_ok = True
else:
    print("‚ùå GPU kh√¥ng available!")
    print("   Vui l√≤ng ch·ªçn Runtime ‚Üí Change runtime type ‚Üí GPU")
    print("   Sau ƒë√≥ restart runtime v√† ch·∫°y l·∫°i cell n√†y")
    gpu_ok = False

# ============================================
# CELL 7: T√¨m Checkpoint (N·∫øu Resume)
# ============================================
log_checkpoint_dir = f"{log_dir}/vi_lora/lightning_logs"
checkpoints = glob.glob(f"{log_checkpoint_dir}/*/checkpoints/*.ckpt") if os.path.exists(log_checkpoint_dir) else []

if checkpoints:
    latest_checkpoint = max(checkpoints, key=os.path.getctime)
    print(f"‚úì T√¨m th·∫•y checkpoint: {latest_checkpoint}")
    ckpt_path = latest_checkpoint
    resume = True
else:
    print("‚Ñπ Ch∆∞a c√≥ checkpoint, s·∫Ω train t·ª´ ƒë·∫ßu")
    ckpt_path = None
    resume = False

# ============================================
# CELL 8: B·∫Øt ƒê·∫ßu Training
# ============================================
# Tham s·ªë training
dataset_path = "/content/drive/MyDrive/ace_step_data/vi_lora_dataset"
checkpoint_dir = "/content/drive/MyDrive/ace_step_outputs/checkpoints"
log_dir = "/content/drive/MyDrive/ace_step_outputs/logs"

# Build command
cmd = f"""python trainer.py \\
    --num_nodes 1 \\
    --devices 1 \\
    --dataset_path "{dataset_path}" \\
    --exp_name "vi_lora_small" \\
    --lora_config_path "config/vi_lora_config.json" \\
    --learning_rate 1e-4 \\
    --accumulate_grad_batches 4 \\
    --precision 16 \\
    --num_workers 2 \\
    --max_steps 20000 \\
    --every_n_train_steps 100 \\
    --shift 3.0 \\
    --checkpoint_dir "{checkpoint_dir}" \\
    --logger_dir "{log_dir}" \\
    --epochs -1 \\
    --every_plot_step 2000 \\
    --gradient_clip_val 0.5 \\
    --gradient_clip_algorithm "norm" """

# Th√™m --ckpt_path n·∫øu c√≥ checkpoint
if resume and ckpt_path:
    cmd += f'\\\n    --ckpt_path "{ckpt_path}"'

# Ki·ªÉm tra GPU tr∆∞·ªõc khi train
if 'gpu_ok' not in locals() or not gpu_ok:
    print("‚ùå Kh√¥ng th·ªÉ train v√¨ GPU kh√¥ng available!")
    print("   Vui l√≤ng ch·∫°y CELL 6 (Ki·ªÉm tra GPU) tr∆∞·ªõc!")
    print("   Ho·∫∑c ch·ªçn Runtime ‚Üí Change runtime type ‚Üí GPU")
else:
    print("üöÄ B·∫Øt ƒë·∫ßu training...")
    print("=" * 60)
    print(cmd)
    print("=" * 60)
    
    # Ch·∫°y training
    !{cmd}

# ============================================
# CELL 9: Monitor Training (Optional)
# ============================================
# Ch·∫°y cell n√†y trong tab m·ªõi ƒë·ªÉ xem log real-time
# (Kh√¥ng ch·∫°y c√πng l√∫c v·ªõi training)

# log_dir = "/content/drive/MyDrive/ace_step_outputs/logs/vi_lora/lightning_logs"
# log_files = glob.glob(f"{log_dir}/*/events.out.tfevents.*")
# if log_files:
#     latest_log = max(log_files, key=os.path.getctime)
#     !tail -f {latest_log}

